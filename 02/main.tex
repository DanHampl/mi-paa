
\NeedsTeXFormat{LaTeX2e}
\LoadClass{article}
\RequirePackage{todonotes}
\RequirePackage[parfill]{parskip}
\RequirePackage[margin=2.8cm]{geometry}
\RequirePackage{hyperref}
\RequirePackage[english]{babel}
\RequirePackage{pgfplots}
\RequirePackage{listings}
\RequirePackage{amsfonts}
\RequirePackage{subfiles}
\RequirePackage{mathtools}
\RequirePackage[noabbrev,capitalize,nameinlink]{cleveref}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\begin{document}
\title{\textbf{NI-KOP~--~Task 2}\\
    Optimisation version of the 0/1 knapsack problem}
\author{Daniel Hampl (hampldan)}
\date{\today}
\maketitle

\tableofcontents
\newpage

\section{Introduction}
The knapsack problem is one of the most widespread NP-Complete problems. It can be described as having a knapsack with a limited capacity and multiple items, where each of these items has a set value and weight. Our task is to fill the knapsack with items of highest combined value possible.

In this paper, we will be focussing approximation algorithms solving the knapsack problem and the deviation of results provided by these approximation algorithms.

\subsection{Definition\cite{WEBSITE:knapsackDef}}
We have weight $W$ and $n$ items, where item $i$ is described as a pair $(w_i, v_i)$.

\begin{itemize}
    \item $w_i$ is a weight of object $n_i$
    \item $v_i$ is a value of object $n_i$
    \item $w_i, v_i \in \mathbb{N}\setminus\{0\}$
\end{itemize}

Find value $V$, where:

\begin{itemize}
    \item $\sum_i(x_i*v_i) = V$
    \item $\sum_i(x_i*w_i) \leq W$
    \item $x_i \in \{0,1\} \forall i$
\end{itemize}

\subsection{Task}
Implement solution for the optimisation version of the knapsack problem in four versions.

\begin{itemize}
    \item Dynamic programing with decomposition by value or weight
    \item Simple greedy heuristic approximation
    \item Modification of this greedy heuristics, where only the single most valuable item is selected
    \item FPTAS algorithm
\end{itemize}

Experimentally evaluate the dependence of computational complexity on instance size. And deviation of results provided by approximation algorithms as compared to the exact results. 

\input{data/tex/fullTime.tex}

% \input{data/tex/cutTime.tex}

\input{data/tex/deviation.tex}

% \input{data/tex/deviationCut.tex}

% \input{data/tex/deviationCut2.tex}


\section{Implementation}
All of these algorithms are implemented in Python 3.7, and all data were gathered on the Windows 10 OS running on Intel(R) Core(TM) i7-6700HQ CPU @ 2.60GHz.

For testing of these algorithms, we have used two data sets. The first one with randomly generated values and the second with purposefully hard data. However, in the randomly generated set, we can see a deviation in the dataset with twenty items. This deviation can be seen in \cref{plot:deviation,plot:maxDev,plot:devFptas}.


\subsection{Brute force algorithm}
The brute force algorithm is indifferent to any changes to a dataset by design, as it has to test every option before returning our solution, thus having the same average time complexity in all our test cases.

\subsection{Branch \& bounds algorithm}
As we observe the branch and bounds algorithm, we can see its relatively low complexity, which is mostly thanks to our data having considerably high knapsack with the 0.8 ratio between knapsacks load capacity and the combined weight of all the items. Thanks to this setup, the B\&B algorithm can skip a significant part of combinations, as it can add most of the elements. This difference can be observed in \cref{plot:fullTime}.

\subsection{Dynamic programing}
Our task was to use dynamic programming for solving the optimisation version of the 0/1 knapsack problem, for which we have selected the decomposition by value, due to its similarity with the FPTAS algorithm.

For more information about Dynamic programming or exact algorithm, feel free to look at the code attached or \cite[Moodle textbook]{WEBSITE:dynamicKnapsack}.

\subsection{Greedy heuristics}
The greedy algorithm sorts the elements given at input by the value to weight ratio. It adds as many elements as possible with the preference given to the items with the highest value and lowest weight.

This approach might not seem too precise, but it offers much lower complexity with $\mathbb{O}(n \log(n))$, where the most complex task is to sort the data.

\subsection{Modified greedy heuristics}
The modified greedy algorithm takes the maximum value item and compares it to the result of the basic greedy algorithm mentioned above. Afterwards, it takes the better of these results, which will be the result of our algorithm.

This algorithm allows us to approximate the result with the same complexity as the basic greedy heuristics, with a slight improvement in precision, as can be seen in \cref{plot:fptasTime}.

\subsection{FPTAS}

The FPTAS algorithm is basically the same as the decomposition by price used in dynamic programming.
The only difference here is that we lower the values of all the items, which lowers the complexity
of the algorithm and in this case, allows us to limit the imprecision.

In \cref{plot:fullTime,plot:deviation} we have set the highest deviation to be 0.5 and from 0.1 to 0.9 for \cref{plot:fptasTime,plot:devFptas}.
In order to gain precise data for selected maximal imprecisions, we have used the following formula.

\begin{itemize}
    \item $C_M = $max$\{c_1,c_2, ... c_n\}$
    \item $K = \dfrac{\epsilon C_M}{n}$
    \item $c_i' = \lfloor\dfrac{c_i}{K}\rfloor$
\end{itemize}

In \cref{plot:fptasTime,plot:devFptas} we can see the average time complexity and imprecision, respectively. From these graphs, we can clearly see the lowering time complexity with higher imprecision, as well as the lowering average imprecision, as the size of the set grows. 
% \input{data/tex/fptasRatio.tex}
\input{data/tex/fptasTime.tex}
\input{data/tex/fptasDeviation.tex}
\input{data/tex/fptasMaxDeviation.tex}
\input{data/tex/allMaxDeviation.tex}

\newpage

\section{Conclusion}
In conclusion, we have created six implementations for solving the optimisation version of the 0/1 knapsack problem. We have compared the efficiency of these implementations with respect to processor time and their precision. This comparison was made on randomly generated data set as well as on a purposefully hard dataset. However, the difference between those two datasets did not appear to be particularly apparent, which might have been caused by the concrete implementation.

Furthermore,  we have also compared the time complexity and the imprecision within the FPTAS algorithm for multiple maximal imprecisions. From these, we have selected few to show in \cref{plot:fptasTime,plot:devFptas}.

\newpage
\bibliographystyle{iso690}
\nocite{*} % all entries in the bib file
\bibliography{database.bib}

\end{document}